MultiCategorical
logisticRegression=0
crossValidation=2
mars output
L1 Absolute error:   0.947892
L1 Relative error:   0.415861
L2 Absolute error:    1.09442
L2 Relative error:   0.280179
Linf Absolute error:          2
pymars output
 MARS modeling, version 4.0 (7/13/09)
 input parameters (see doc.):
     n    p    nk   ms    mi   df     il   fv    ic 
   1000   3    5    0     1    3.0    0    0.0    0
 predictor variable flags:

 var:    1  2  3

 flag:   -1  -1  -1

 ordinal response:

          min          n/4          n/2          3n/4         max
           0            4            6           13           21 

 there are   3 categorical predictor variables.
 categorical variable   1 has   5 values.
 value     internal code     counts
     0             1             200
     1             2             200
     2             3             200
     3             4             200
     4             5             200
 categorical variable   2 has   2 values.
 value     internal code     counts
     0             1             500
     1             2             500
 categorical variable   3 has   3 values.
 value     internal code     counts
     0             1             300
     1             2             300
     2             3             400

 cvmars output

 sample reuse to estimate df:
   2 - fold cross-validation.

 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
    0          38.12      0.0      1.0
  2    1        10.08     1.0     4.0         1            00011                
  4    3        4.322     2.0     7.0         1            11010                
    5           1.326     3.0    10.0         3             001                 

  final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:      5.9281     10.0890      0.0000     -4.8884      0.0000      3.4797
   (piecewise linear) gcv =        1.326   #efprms =  10.0

 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
    0          38.45      0.0      1.0
  2    1        10.15     1.0     4.0         1            00011                
  4    3        4.177     2.0     7.0         1            11010                
    5           1.163     3.0    10.0         3             001                 

  final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:      6.0804      9.9139      0.0000     -5.1146      0.0000      3.5184
   (piecewise linear) gcv =        1.163   #efprms =  10.0

  #bsfns      df         asr           gcv           cv
     5      -1.50        1.195          1.2        1.214
     3      88.40        1.195        2.933        1.214
     2     186.59        4.131        16.76        4.166
     1     279.75        9.952        25.64        10.04
     0     364.62        38.13        38.29        38.16
estimated optimal df(   3 ) =   88.40 with (estimated) pse =        1.214

 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
    0          38.22      0.0      1.0
  2    1        11.31     1.0    60.9         1            00011                
  4    3        5.357     2.0   120.9         1            11010                
    5           1.788     3.0   180.8         3             001                 

  final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:      6.0000     10.0000      0.0000     -5.0000      0.0000      3.5000
   (piecewise linear) gcv =        1.788   #efprms = 180.8
 anova decomposition on   3 basis functions:
  fun. std. dev.     -gcv    #bsfns  #efprms  variable(s)
   1      3.216      11.31      2    1.2e+02       1
   2      1.715      5.357      1      60       3

 piecewise cubic fit on   3  basis functions, gcv =        1.788

 gcv removing each variable:
       1       2       3

     39.92     1.788     5.357

 relative variable importance:
       1       2       3

       100         0     30.59

Returned from python mars
L1 Absolute error:   0.947892
L1 Relative error:   0.415861
L2 Absolute error:    1.09442
L2 Relative error:   0.280179
Linf Absolute error:          2
