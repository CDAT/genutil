CategoricalTest
logisticRegression=1
crossValidation=2
mars output
L1 Absolute error:   0.725789
L1 Relative error:   0.741045
L2 Absolute error:   0.964012
L2 Relative error:   0.976683
Linf Absolute error:    2.99885
pymars output
 MARS modeling, version 4.0 (7/13/09)
 input parameters (see doc.):
     n    p    nk   ms    mi   df     il   fv    ic 
    400   3    5    0     1    3.0    1    0.0    0
 predictor variable flags:

 var:    1  2  3

 flag:   1  -1  1

(/ binary (0/1) response:  mass(0) =       0.6825,   mass(1) =       0.3175)

 there are   2 ordinal predictor variables.
  var          min         n/4         n/2        3n/4            max 
   1          220          520          580          660          800
   3         2.26         3.13         3.39         3.67            4

 there are   1 categorical predictor variables.
 categorical variable   2 has   2 values.
 value     internal code     counts
     0             1             335
     1             2              65

 cvmars output

 sample reuse to estimate df:
   2 - fold cross-validation.

 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
    0         0.2179      0.0      1.0
    1         0.2144     1.0      4.0       1            220              
  3    2       0.2194     2.0     7.0         2              10                 
    4         0.2253     3.0     10.0       3           2.26              
    5         0.2301     3.0     12.0       3           2.26              

  final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:      0.0151      0.0008      0.0000      0.0000      0.0000      0.0000
   (piecewise linear) gcv =       0.2159   #efprms =   4.7

 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
    0         0.2198      0.0      1.0
    1         0.2183     1.0      4.0       3           2.26              
  3    2       0.2222     2.0      7.0      3           3.31              
  5    4       0.2208     3.0     10.0      3           3.64              

  final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:      0.1997      0.0000      1.1221      0.0000     -1.5977      0.0000
   (piecewise linear) gcv =       0.2155   #efprms =   7.0

  #bsfns      df         asr           gcv           cv
     5      -1.31       0.2013       0.2031       0.2121
     3      -0.91       0.2013       0.2051       0.2121
     2       0.43       0.2025       0.2102        0.212
     1       3.16       0.2065        0.216       0.2123
     0       4.94       0.2167       0.2189       0.2167
estimated optimal df(   2 ) =    0.43 with (estimated) pse =        0.212

 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
    0         0.2178      0.0      1.0
    1         0.2117     1.0      2.3       1            220              
    2         0.2101     2.0      3.6       3           2.26              
  4    3       0.2101     3.0     4.9         2              10                 
    5          0.2104     3.0     5.2         2              10                 

  final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:     -0.0586      0.0005      0.1542      0.0000      0.0000      0.0000
   (piecewise linear) gcv =       0.2103   #efprms =   3.8

 piecewise-linear logistic gcv =       0.2106   ave var=      0.2063

 logit anova decomposition on   2  basis functions:
  fun.    -gcv    #bsfns  #efprms  variable(s)
  1         0.2121      1      1.4          1
  2         0.2119      1      1.4          3

 piecewise cubic fit on   2  basis functions, gcv =       0.2103
 piecewise-cubic logistic gcv =       0.2106   ave var =      0.2063

 gcv removing each variable:
       1       2       3

    0.2121    0.2106    0.2119

 relative variable importance:
       1       2       3

       100         0     95.03

Returned from python mars
L1 Absolute error:   0.725789
L1 Relative error:   0.741045
L2 Absolute error:   0.964012
L2 Relative error:   0.976683
Linf Absolute error:    2.99885
