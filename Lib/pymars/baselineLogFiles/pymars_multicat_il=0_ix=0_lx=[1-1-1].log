MultiCategoricalTest
logisticRegression=0
crossValidation=0
mars output
L1 Absolute error:   0.481118
L1 Relative error:   0.411677
L2 Absolute error:    0.26801
L2 Relative error:   0.277049
Linf Absolute error:      0.525
pymars output
 MARS modeling, version 4.0 (7/13/09)
 input parameters (see doc.):
     n    p    nk   ms    mi   df     il   fv    ic 
   1000   3    5    0     1    3.0    0    0.0    0
 predictor variable flags:

 var:    1  2  3

 flag:   1  -1  -1

 ordinal response:

          min          n/4          n/2          3n/4         max
           0         1.09         2.09         4.49         5.81 

 there are   1 ordinal predictor variables.
  var          min         n/4         n/2        3n/4            max 
   1            0          0.2          0.4          0.7          0.9

 there are   2 categorical predictor variables.
 categorical variable   2 has   2 values.
 value     internal code     counts
     0             1             500
     1             2             500
 categorical variable   3 has   3 values.
 value     internal code     counts
     0             1             300
     1             2             300
     2             3             400

 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
    0          3.419      0.0      1.0
  2    1       0.4759     1.0     4.0         3             001                 
  4    3       0.2252     2.0     7.0         2              10                 
    5         0.07357     3.0    10.0         3             100                 

  final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:      2.2850      3.0000      0.0000     -1.0000      0.0000     -1.0000
   (piecewise linear) gcv =      0.07357   #efprms =  10.0
 anova decomposition on   3 basis functions:
  fun. std. dev.     -gcv    #bsfns  #efprms  variable(s)
   1     0.4583     0.5945      2       6       3
   2        0.5     0.2834      1       3       2

 piecewise cubic fit on   3  basis functions, gcv =      0.07357

 gcv removing each variable:
       1       2       3

   0.07357    0.3267     3.188

 relative variable importance:
       1       2       3

         0     28.51       100

Returned from python mars
L1 Absolute error:   0.481118
L1 Relative error:   0.411677
L2 Absolute error:    0.26801
L2 Relative error:   0.277049
Linf Absolute error:      0.525
