
 MARS modeling, version 3.6 (3/25/93)


 input parameters (see doc.):
    n     p    nk    ms    mi     df    il    fv     ic
   400    3     5     0     1   3.000    1  0.000     0

 predictor variable flags:
 var:    1  2  3
 flag:   1 -1  1

 binary (0/1) response:  mass(0) =  0.6825       mass(1) =  0.3175    

 there are  2 ordinal predictor variables.

  var     min         n/4         n/2        3n/4         max
   1    220.0       520.0       580.0       660.0       800.0    
   3    2.260       3.130       3.390       3.670       4.000    

 there are  1 categorical predictor variables.

 categorical variable  2 has  2 values.
  value     internal code     counts
    0.            1            335
    1.            2             65

 sample reuse to estimate df:
   2 - fold cross-validation.



 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
     0      0.2179         0.0     1.0
     1      0.2144             1         4             1     220.0            0
   3   2    0.2194             2         7             2            10                0
     4      0.2253             3        10             3     2.260            0
     5      0.2301             3        12             3     2.260            0

 final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:  0.1508E-01  0.8201E-03   0.000       0.000       0.000       0.000    

   (piecewise linear) gcv =   0.2159       #efprms =   4.7


 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
     0      0.2198         0.0     1.0
     1      0.2183             1         4             3     2.260            0
   3   2    0.2222             2         7             3     3.310            0
   5   4    0.2208             3        10             3     3.640            0

 final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef:  0.1997       0.000       1.122       0.000      -1.598       0.000    

   (piecewise linear) gcv =   0.2155       #efprms =   7.0
  #bsfns     df        asr           gcv           cv
     5 -0.13D+01    0.2013        0.2031        0.2121    
     3 -0.91D+00    0.2013        0.2051        0.2121    
     2  0.43D+00    0.2025        0.2102        0.2120    
     1  0.32D+01    0.2065        0.2160        0.2123    
     0  0.49D+01    0.2167        0.2189        0.2167    

 estimated optimal df(  2) =   0.43 with (estimated) pse =  0.2120    


 forward stepwise knot placement:

  basfn(s)    gcv      #indbsfns  #efprms   variable      knot            parent
     0      0.2178         0.0     1.0
     1      0.2117             1         2             1     220.0            0
     2      0.2101             2         4             3     2.260            0
   4   3    0.2101             3         5             2            10                0
     5      0.2104             3         5             2            10                    0

 final model after backward stepwise elimination:

 bsfn:       0           1           2           3           4           5    
 coef: -0.5860E-01  0.5489E-03  0.1542       0.000       0.000       0.000    

   (piecewise linear) gcv =   0.2103       #efprms =   3.8

 piecewise-linear logistic gcv =  0.2106       ave var =  0.2063    

 logit anova decomposition on  2 basis functions:
  fun.    -gcv    #bsfns  #efprms  variable(s)
   1   0.2121        1      1.4       1
   2   0.2119        1      1.4       3

 piecewise cubic fit on  2 basis functions, gcv =  0.2103    

 piecewise-cubic logistic gcv =  0.2106       ave var =  0.2063    

 -gcv removing each variable:

        1           2           3        
   0.2121      0.2106      0.2119    

 relative variable importance:

        1           2           3        
    100.0       0.000       95.03    

 MARS run time =      0.003906 seconds
